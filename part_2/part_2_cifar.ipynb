{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/helium2/arjun/.conda/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[0.5058918137254902, 0.4859552125459559, 0.4411151014859069]\n",
      "[0.26766681344702586, 0.2560914330229496, 0.27595397525087484]\n"
     ]
    }
   ],
   "source": [
    "# Get transform\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True)\n",
    "\n",
    "# Stick all the images together to form a 1600000 X 32 X 3 array\n",
    "x = np.concatenate([np.asarray(trainset[i][0]) for i in range(len(testset))])\n",
    "\n",
    "# calculate the mean and std along the (0, 1) axes\n",
    "mean = np.mean(x, axis=(0, 1))/255\n",
    "std = np.std(x, axis=(0, 1))/255\n",
    "# the the mean and std\n",
    "mean=mean.tolist()\n",
    "std=std.tolist()\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 1: Download dataset & set up data loader\n",
    "Luckly no custom dataset is needed, we can use CIFAR100 dataset from torchvision\n",
    "'''\n",
    "\n",
    "# Define the transformation using the calculated mean and std\n",
    "mean = [0.5059, 0.4860, 0.4411]\n",
    "std = [0.2677, 0.2561, 0.2759]\n",
    "transform_train = tt.Compose([\n",
    "                         tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         tt.Normalize(mean,std,inplace=True)\n",
    "\t\t\t\t\t\t ])\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "                            tt.ToTensor(), \n",
    "\t\t\t\t\t\t\t tt.Normalize(mean,std)\n",
    "\t\t\t\t\t\t\t ])\n",
    "\n",
    "# define the datasets\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "# define the datasets\n",
    "train_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Step 1.1: lets test the dataloader\n",
    "'''\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.size(), labels.size())\n",
    "    plt.imshow(np.transpose(images[0].numpy(), (1, 2, 0)))\n",
    "    plt.title(labels[0].item())\n",
    "    plt.show()\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 2: Define the model\n",
    "'''\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:03<00:00, 197.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 3.4542848709011076, Training Accuracy: 16.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [01:07<10:04, 67.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 3.1756845607280733, Validation Accuracy: 21.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:07<00:00, 184.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 3.038341246329546, Training Accuracy: 24.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [02:18<09:17, 69.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 2.8311093807935714, Validation Accuracy: 28.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:03<00:00, 196.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 2.7520762230420113, Training Accuracy: 29.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [03:26<08:01, 68.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 2.4562228275835514, Validation Accuracy: 36.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:02<00:00, 198.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 2.546048914480209, Training Accuracy: 34.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [04:33<06:47, 67.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 2.3877445827424526, Validation Accuracy: 38.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:16<00:00, 163.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 2.3865801280647516, Training Accuracy: 37.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [05:53<06:02, 72.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 2.2164074676454066, Validation Accuracy: 41.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:07<00:00, 185.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 2.252488233047724, Training Accuracy: 40.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [07:05<04:48, 72.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Loss: 2.1282087778404355, Validation Accuracy: 44.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:03<00:00, 195.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 2.1461055336129666, Training Accuracy: 42.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [08:12<03:32, 70.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Loss: 2.1242535855829714, Validation Accuracy: 44.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:04<00:00, 193.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 2.066124326152727, Training Accuracy: 44.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [09:21<02:20, 70.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Loss: 2.1192675586134193, Validation Accuracy: 44.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:06<00:00, 188.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 2.001886462891996, Training Accuracy: 46.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [10:31<01:10, 70.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Loss: 2.0886245472699403, Validation Accuracy: 45.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:03<00:00, 195.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 1.9489365218045562, Training Accuracy: 47.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [11:39<00:00, 69.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 1.996133022941649, Validation Accuracy: 47.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {train_loss}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        validation_loss = running_val_loss / len(val_loader)\n",
    "        validation_accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {validation_loss}, Validation Accuracy: {validation_accuracy:.2f}%')\n",
    "\n",
    "# Assuming model, train_loader, val_loader, criterion, optimizer are defined\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
